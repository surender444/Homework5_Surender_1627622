{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Que-:1 The starting state is Rest. Calculate the probability of possible activity on the 15th day. \n\nimport numpy as np\n\n# This is for the statespace\nstate = {\n    0: \"Rest\", 1: \"Sweeties\", 2: \"Exercise\" }\n# Now this here is for the possible number of matrixes\nA = np.array([[0.2, 0.2, 0.6], [0.2, 0.1, 0.7], [0.1, 0.3, 0.6]])\n\nstart_state = 0\ncurr_state = start_state\nn = 15\n\nfor _ in range(n - 1):\n    curr_state = np.random.choice([0, 1, 2], p=A[curr_state])\n\nactivity = state[curr_state]\nprint(\"Possible activity on the 15th day:\", activity)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 30,
      "outputs": [
        {
          "name": "stdout",
          "text": "Possible activity on the 15th day: Sweeties\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "# Que-2-: What about the state and probability after 10000 days?\n\nimport numpy as np\nstate = {\n    0: \"Rest\", 1: \"Sweeties\", 2: \"Exercise\" }\n\nA = np.array([[0.2, 0.2, 0.6], [0.2, 0.1, 0.7], [0.1, 0.3, 0.6]])\n\nstart_state = 0\ncurr_state = start_state\nn = 10000\n\nstate_count = {state_id: 0 for state_id in state}\n\nfor _ in range(n):\n    curr_state = np.random.choice([0, 1, 2], p=A[curr_state])\n    state_count[curr_state] += 1\n\nstate_probabilities = {state_id: count / n for state_id, count in state_count.items()}\n\nprint(\"State counts after 10000 days:\")\nfor state_id, count in state_count.items():\n    print(state[state_id], \":\", count)\n\nprint(\"\\nState probabilities after 10000 days:\")\nfor state_id, prob in state_probabilities.items():\n    print(state[state_id], \":\", prob)\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 31,
      "outputs": [
        {
          "name": "stdout",
          "text": "State counts after 10000 days:\nRest : 1393\nSweeties : 2418\nExercise : 6189\n\nState probabilities after 10000 days:\nRest : 0.1393\nSweeties : 0.2418\nExercise : 0.6189\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "# Que-:3 What do you observe from the above two?\n# Ans-: Activity on day 15: When observing a single occurrence of a Markov chain starting from an \"inactive state,\" the activity on day 15 can vary due to the inherent randomness of the process. The specific activity observed on day 15 is contingent upon the probabilities defined in the transition matrix A.\n\n#State and probability after 10,000 days: By employing a Monte Carlo simulation and running the Markov chain for a substantial number of days (in this instance, 10,000 days), we can collect statistical data regarding the states visited. State counters indicate the frequency of each state being visited, while state probabilities represent the relative occurrence of each state throughout the simulation period. These probabilities provide insights into the long-term behavior of the Markov chain.\n\n#In essence, simulations enable the analysis of both short-term and long-term outcomes of the Markov chain, furnishing information about potential actions and their probabilities at specific time points and over extended durations.",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}